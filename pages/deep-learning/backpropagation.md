# 误差反向传播法

::: danger 警告
该页面尚未完工!
:::

::: details 目录

[[toc]]

:::

## 计算图

**计算图**将计算过程用图形表示出来。这里说的图形是数据结构图，通过多个节点和边表示（连接节点的直线称为“边”）。

计算图通过节点和箭头表示计算过程。节点用 ○ 表示，○ 中是计算的内容。将计算的中间结果写在箭头的上方，表示各个节点的计算结果从左向右传递。

::: details 问题 1

- **问题 1**： 太郎在超市买了 2 个 100 日元一个的苹果，消费税是 10%，请计算支付金额。

![基于计算图求解的问题 1 的答案](/images/deep-learning/backpropagation/question1-answer1.png)

开始时，苹果的 100 日元流到“×2”节点，变成 200 日元，然后被传递给下一个节点。接着，这个 200 日元流向“×1.1”节点，变成 220 日元。因此，从这个计算图的结果可知，答案为 220 日元。

图中把“×2”“ ×1.1”等作为一个运算整体用 ○ 括起来了，不过只用 ○ 表示乘法运算“×”也是可行的。此时，如下所示，可以将“2”和“1.1”分别作为变量“苹果的个数”和“消费税”标在 ○ 外面。

![基于计算图求解的问题 1 的答案：“苹果的个数”和“消费税”作为变量标在○外面](/images/deep-learning/backpropagation/question1-answer2.png)

:::

::: details 问题 2

- **问题 2**： 太郎在超市买了 2 个苹果、3 个橘子。其中，苹果每个 100 日元，橘子每个 150 日元。消费税是 10%，请计算支付金额。

![基于计算图求解的问题 2 的答案](/images/deep-learning/backpropagation/question2.png)

这个问题中新增了加法节点“+”，用来合计苹果和橘子的金额。构建了计算图后，从左向右进行计算。就像电路中的电流流动一样，计算结果从左向右传递。到达最右边的计算结果后，计算过程就结束了。

:::

综上，用计算图解题的情况下，需要按如下流程进行：

- 构建计算图；

- 在计算图上，从左向右进行计算。

这里的第 2 歩“从左向右进行计算”是一种正方向上的传播，简称为**正向传播**（forward propagation）。正向传播是从计算图出发点到结束点的传播。

当然也可以考虑反向（从图上看的话，就是从右向左）的传播。实际上，这种传播称为**反向传播**（backward propagation）。

### 局部计算

计算图的特征是可以通过传递“局部计算”获得最终结果。“局部”这个词的意思是“与自己相关的某个小范围”。局部计算是指，无论全局发生了什么，都能只根据与自己相关的信息输出接下来的结果。

::: details 示例

比如，在超市买了2个苹果和其他很多东西：

![买了2个苹果和其他很多东西的例子](/images/deep-learning/backpropagation/buy-many.png)

> 假设（经过复杂的计算）购买的其他很多东西总共花费 4000 日元。

这里的重点是，各个节点处的计算都是局部计算。

这意味着，例如苹果和其他很多东西的求和运算（4000 + 200 → 4200）并不关心 4000 这个数字是如何计算而来的，只要把两个数字相加就可以了。

换言之，各个节点处只需进行与自己有关的计算（在这个例子中是对输入的两个数字进行加法运算），不用考虑全局。

:::

计算图可以集中精力于局部计算。无论全局的计算有多么复杂，各个步骤所要做的就是对象节点的局部计算。虽然局部计算非常简单，但是通过传递它的计算结果，可以获得全局的复杂计算的结果。

### 计算图的优点

- 无论全局是多么复杂的计算，都可以通过局部计算使各个节点致力于简单的计算，从而简化问题；

- 利用计算图可以将中间的计算结果全部保存起来（比如，计算进行到2个苹果时的金额是 200 日元、加上消费税之前的金额 650 日元等）；

- 可以通过正向传播和反向传播高效地计算各个变量的导数值。

::: details 重审问题 1

问题1中，我们计算了购买2个苹果时加上消费税最终需要支付的金额。

这里，假设我们想知道苹果价格的上涨会在多大程度上影响最终的支付金额，即求“支付金额关于苹果的价格的导数”。设苹果的价格为 $x$，支付金额为 $L$，则相当于求 $\frac{\partial L}{\partial x}$。这个导数的值表示当苹果的价格稍微上涨时，支付金额会增加多少。

可以通过计算图的反向传播求导数：

![基于反向传播的导数的传递](/images/deep-learning/backpropagation/question1-reverse.png)

如图所示，反向传播使用与正方向相反的箭头（粗线）表示。反向传播传递“局部导数”，将导数的值写在箭头的下方。

在这个例子中，反向传播从右向左传递导数的值（1 → 1.1 → 2.2）。从这个结果中可知，“支付金额关于苹果的价格的导数”的值是 2.2。这意味着，如果苹果的价格上涨 1 日元，最终的支付金额会增加 2.2 日元（严格地讲，如果苹果的价格增加某个微小值，则最终的支付金额将增加那个微小值的 2.2 倍）

这里只求了关于苹果的价格的导数，不过“支付金额关于消费税的导数”“支付金额关于苹果的个数的导数”等也都可以用同样的方式算出来。并且，计算中途求得的导数的结果（中间传递的导数）可以被共享，从而可以高效地计算多个导数。

:::

## 链式法则

前面介绍的计算图的正向传播将计算结果正向（从左到右）传递，其计算过程是我们日常接触的计算过程，所以感觉上可能比较自然。

而反向传播将局部导数向正方向的反方向（从右到左）传递，一开始可能会让人感到困惑。传递这个局部导数的原理，是基于**链式法则**（chain rule）的。

### 计算图的反向传播

假设存在 $y = f(x)$ 的计算，这个计算的反向传播如下图所示：

![计算图的反向传播：沿着与正方向相反的方向，乘上局部导数](/images/deep-learning/backpropagation/chart-backpropagation.png)

反向传播的计算顺序是，**将信号 $E$ 乘以节点的局部导数**（$\frac{\partial y}{\partial x}$），**然后将结果传递给下一个节点**。

> 这里所说的局部导数是指正向传播中 $y=f(x)$ 的导数，也就是 y 关于 x 的导数（$\frac{\partial y}{\partial x}$）。
>
> 比如，假设 $y=f(x)=x^2$，则局部导数为 $\frac{\partial y}{\partial x}=2x$。把这个局部导数乘以上游传过来的值（本例中为 $E$），然后传递给前面的节点。

通过这样的计算，可以高效地求出导数的值，这是反向传播的要点。

### 什么是链式法则

链式法则是关于复合函数的导数的性质，定义如下：

- 如果某个函数由复合函数表示，则该复合函数的导数可以用构成复合函数的各个函数的导数的乘积表示。

::: details 什么是复合函数

复合函数是由多个函数构成的函数。比如，$z=(x+y)^2$ 是由下面两个式子构成的：

$$z=t^2$$

$$t=x+y$$

:::

### 链式法则和计算图

现在我们尝试将 $z=(x+y)^2$ 的链式法则的计算用计算图表示出来。如果用“\*\*2”节点表示平方运算的话，则计算图如下图所示：

![计算图：沿着与正方向相反的方向，乘上局部导数后传递](/images/deep-learning/backpropagation/chain-backpropagation.png)

如图所示，计算图的反向传播从右到左传播信号。反向传播的计算顺序是：先将节点的输入信号乘以节点的局部导数（偏导数），然后再传递给下一个节点。

比如，反向传播时，“\*\*2”节点的输入是 $\frac{\partial z}{\partial x}$，将其乘以局部导数 $\frac{\partial z}{\partial t}$（因为正向传播时输入是 $t$、输出是 $z$，所以这个节点的局部导数是 $\frac{\partial z}{\partial t}$），然后传递给下一个节点。

另外，上图中反向传播最开始的信号 $\frac{\partial z}{\partial z}$ 在前面的数学式中没有出现，这是因为 $\frac{\partial z}{\partial z}=1$，所以在刚才的式子中被省略了。

需要注意的是最左边的反向传播的结果。根据链式法则，$\frac{\partial z}{\partial z}\frac{\partial z}{\partial t}\frac{\partial t}{\partial x}=\frac{\partial z}{\partial t}\frac{\partial t}{\partial x}=\frac{\partial z}{\partial x}$ 成立，对应“z关于x的导数”。也就是说，反向传播是基于链式法则的。

结果如下图所示，$\frac{\partial z}{\partial x}$ 的结果为 $2(x+y)$：

![根据计算图的反向传播的结果](/images/deep-learning/backpropagation/chain-backpropagation-result.png)

## 反向传播
