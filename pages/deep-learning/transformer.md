# Transformer

::: danger 警告

该页面尚未完工!

:::

::: details 目录

[[toc]]

:::

## 什么是 Transformer

::: danger 警告

该部分尚未完工!

:::

**Transformer** 是一种深度学习模型架构，它在 2017 年由 Google 的研究人员在论文《Attention Is All You Need》中首次提出。它彻底改变了自然语言处理（NLP）领域，并成为当今几乎所有尖端 AI 模型（如 ChatGPT、BERT、GPT 系列）的核心基础。

简单来说，Transformer 是一种专门设计用来处理序列数据（例如句子、语音、时间序列）的模型，但它摒弃了传统的循环神经网络（RNN）和卷积神经网络（CNN）结构，完全基于一种名为 "自注意力机制" 的技术。

Transformer 模型主要由两大模块堆叠而成：**编码器**（Encoder）和**解码器**（Decoder）。

## 编码器

::: danger 警告

该部分尚未完工!

:::

编码器读取并理解输入序列（例如一个英文句子），提取其含义和所有词之间的关系，输出一个包含丰富上下文信息的 "编码"。

## 词嵌入

### 处理文字

文字是相当好的，我们可以用它们来传达各种酷炫的想法。

不幸的是，许多机器学习算法，包括神经网络，并不擅长处理文字。

所以，如果我们想把文字输入神经网络或其他一些机器学习算法，我们需要一种方法将文字转换成数字。

一种非常简单的将文字转换成数字的方法就是为每个词分配一个随机数字。

::: details 具体示例

如果有人刚看完热门电影《Troll 2》并说："Troll 2 is great"，我们可以为每每个词分配一个随机数字：

- Troll 2 --> 12

- is --> -3.05

- great --> 4.2

如果下一个人说："Trolls 2 is awesome"，那么我们可以重新使用我们已经为 "Trolls 2" 和 "is" 选择的随机数字，并为新词 "awesome" 分配一个新的随机数字：

- Troll 2 --> 12 <-- Troll 2

- is --> -3.05 <-- is

- great --> 4.2

- awesome --> -32.1

:::

理论上这是可行的。

但这意味着尽管 "great" 和 "awesome" 意思相似并且用法相似，它们关联的数字却大不相同。

这意味着神经网络在训练中可能需要更多的复杂性。（因为学会正确处理词 "great" 不会帮助神经网络正确使用词 "awesome"）

所以如果用法相似的相似词能够被赋予相似的数字就好了，这样学会使用一个词就能同时帮助学会使用另一个词。而且因为同一个词可以在不同的语境中使用，或变成复数、或以其他方式使用，为每个词分配多个数字可能会很好。这样神经网络可以更容易地适应不同的语境。

::: details 具体示例

例如，词 "great" 可以用在积极的方式："StatQuest is great!"

它也可以以讽刺负面的方式使用："My cellphone's broken, great."

所以，如果我们有一个数字，能够记录 "great" 使用的积极方式和另一个数字来记录负面方式，那将很棒。

:::

好消息是，我们可以让一个超级简单的神经网络为我们完成所有工作。使用神经网络的优势是它可以使用训练数据集中词汇的上下文，来优化可用于嵌入的权重。

### 数字与词的关联

假设我们有两个短语："Trolls 2 is great" 和 "Gymkata 2 is great"。

为了创建一个神经网络来弄清楚我们应该将哪些数字与每个词关联，我们首先为每个独特的词创建输入：

<img src="/images/deep-learning/transformer/words-input.png" alt="词的输入" width="60" />

> 在这个例子中我们的训练数据中有四个独特的词，因此我们有四个输入

现在我们将每个输入链接到至少一个激活函数：

<img src="/images/deep-learning/transformer/words-activation.png" alt="词的激活" width="160" />

> 这个激活函数使用恒等函数

激活函数的数量对应我们想要与每个词关联的数字数量，并且这些连接上的权重最终会是我们与每个词关联的数字。

如果我们想要与每个词关联两个数字，这意味着我们将使用两个激活函数，并且连接到第二个激活函数的权重将是与每个词关联的另一个数字：

<img src="/images/deep-learning/transformer/words-activation-two.png" alt="两个激活函数" width="170" />

像往常一样，这些权重一开始都是随机值，这些权重将通过反向传播进行优化。

现在，为了进行反向传播，我们必须做出预测。所以我们将使用输入词来预测短语中的下一个词。

如果短语是 "Troll 2 is great"，那么我们可以使用词 "Troll 2" 来预测词 "is"。

换句话说，如果输入词是 "Troll 2"，我们通过在 "Troll 2" 的输入中放置 1 来指示这一点，并在所有其他输入中放置 0。那么我们希望下一个词 "is" 的输出具有最大值：

<div style="display: flex;align-items: center;">

<img src="/images/deep-learning/transformer/words-prediction-1000.png" alt="输入 Troll 2" width="60" />

——> 经过计算 ——>

<img src="/images/deep-learning/transformer/words-result-0100.png" alt="输出 is" width="60" />

</div>

同理，如果输入词是 "is"，这意味着 "is" 的输入是 1，所有其他输入都是 0，那么我们希望下一个词 "great" 的输出具有最大值。

<div style="display: flex;align-items: center;">

<img src="/images/deep-learning/transformer/words-prediction-0100.png" alt="输入 is" width="60" />

——> 经过计算 ——>

<img src="/images/deep-learning/transformer/words-result-0010.png" alt="输出 great" width="60" />

</div>

为了做出这些预测，我们将激活函数连接到输出，并在这些连接上添加随机初始化值的权重。

然后我们通过 Softmax 函数运行输出，因为我们有多个分类输出。

![预测结果](/images/deep-learning/transformer/words-softmax.png)

这意味着我们可以使用交叉熵损失函数进行反向传播。

再次强调，目标是训练这个神经网络，以便它能正确预测短语中的下一个词。

### 可视化

假设在训练之前，该神经网络能正确处理 "Troll 2" 的输入计算并正确预测下一个词 "is"：

![正确预测](/images/deep-learning/transformer/words-prediction-true.png)

但还无法正确处理 "is" 的输入计算并预测：

![错误预测](/images/deep-learning/transformer/words-prediction-false.png)

所以我们需要训练这个神经网络。

在我们优化所有权重之前，我们可以在图表上绘制每个词

![词的图表](/images/deep-learning/transformer/words-graph.png)

> 图表的 x 轴是连接到顶部激活函数的权重值，y 轴是连接到底部激活函数的权重值

我们现在看到，词 "Troll 2" 和 "Gymkata" 现在并不接近相比训练数据中的其他词汇。

然而，由于这两个词在训练数据中出现在相同的上下文中，我们希望反向传播会使它们的权重变得更加相似。

![词的图表 2](/images/deep-learning/transformer/words-graph-2.png)

当我们使用新的权重绘制词汇时，我们看到 "Troll 2" 和 "Gymkata" 现在相对于其他词汇更接近。

此时再进行 "Troll 2" 和 "Gymkata" 的预测，我们会会得到我们想要的结果。

总结一下：

- 首先，我们不是随机分配数字给词汇，而是训练一个相对简单的神经网络来为我们分配数字。这可以使相似的词汇最终具有相似的嵌入。

- 最后，具有相似嵌入的相似词汇意味着训练一个处理语言的神经网络更容易，因为学习一个词的使用有助于学习如何使用相似的词。

截至目前，我们展示了我们可以训练一个神经网络来预测每个短语中的下一个词。但是仅仅预测下一个词并没有给我们提供足够的上下文来理解每个词。

所以现在让我们学习新的策略使得用于包含更多的上下文。

### Word2Vec

Word2Vec 是一种流行的创建词嵌入的方法，可以用于包含更多的上下文。

Word2Vec 包含两种方法： **连续词袋**（Context Bag of Words）和 **跳跃模型**（SkipGram）。

连续词袋方法通过使用周围的词来预测中间发生的词来增加语境。

::: details 具体示例

例如，连续词袋方法可能使用词 "Troll 2" 和 "great" 来预测它们之间的词，即 "is"。

:::

跳跃模型方法通过使用中间的词来预测周围的词来增加语境。

::: details 具体示例

例如，跳跃模型方法可以使用词 "is" 来预测周围的词 "Troll 2"、"great" 和 "Gymkata"。

:::

最后，在结束之前，请知道在实践中，人们通常不是仅使用两个激活函数来为每个词语创建两个词嵌入。人们通常使用 100 个或更多的激活函数来为每个词创建大量的嵌入。而且不是使用两个句子进行训练，它们使用整个维基百科。

因此，Word2Vec 不是只有四个单词和短语的词汇量，而是可能拥有大约 300 万词的词汇表。

![Word2Vec](/images/deep-learning/transformer/word2vec.png)

因此，我们需要优化的这个神经网络中的权重总数是 300 万词汇，至少乘以 100（每个词到激活函数的权重的数量），再乘以 2（从激活函数到输出的权重也是 300 万乘以 100），总共 6 亿个权重。因此训练可能会很慢。

然而，Word2Vec 加速的一种方式是采用**负采样**，随机选择一部分我们不想预测哪些用于优化的单词。

::: details 具体示例

例如，假设我们想要预测单词 "aardvark" 来预测单词 "A"。

这意味着只有单词 "aardvark" 中有一个 1，而所有其他单词都是 0。

<img src="/images/deep-learning/transformer/words-prediction-aardvark.png" alt="预测单词 aardvark" width="60" />

这意味着我们可以忽略来自除了 "aardvark" 之外所有其他单词的权重，因为其他单词将他们的权重乘以 0。

![忽略权重](/images/deep-learning/transformer/words-ignore-weights.png)

这单独就从这个优化步骤中移除了接近 3 亿个权重。

然而，激活函数之后我们仍然有 3 亿个权重。

因为我们想预测单词 "A"，不想预测 "aardvark"、"abandon" 和所有其他单词。所以在这个例子中，让我们想象 Word2Vec 随机选择 "abandon" 作为我们不想预测的单词。

> 实际上，Word2Vec 会选择我们不想预测的 2 至 20 个单词，这个例子中我们只选择了 1 个 "abandon"

所以现在，Word2Vec 只使用 "A" 和 "abandon" 的输出值。这意味着在这轮反向传播中，我们可以忽略导致所有其他可能输出的权重：

![忽略权重 2](/images/deep-learning/transformer/words-ignore-weights-2.png)

所以最终，在这个神经网络中总共有 6 亿个权重，我们每步只优化 300 个。这是 Word2Vec 有效创建大词汇量中每个单词的大量词嵌入的一种方式。

:::

## 位置编码

::: danger 警告

该部分尚未完工!

:::

位置编码是一种为 Transformer 模型提供词语在序列中 "顺序" 和 "位置" 信息的技术。 它是解决 Transformer 核心缺陷——"自身不具备理解顺序能力"——的关键。

::: details Transformer 的 "先天缺陷"

Transformer 的核心是自注意力机制。它的工作方式是：当处理一个句子时，它会同时关注句子中的所有词，然后根据重要性加权求和。

但这种 "同时处理" 的方式，意味着模型天然地丢失了词的顺序信息。

例如，对于模型来说，句子 "我爱中国" 和 "中国爱我" 的输入（在没有位置信息时）是一模一样的，因为都是由 "我"、"爱"、"中国" 这三个词组成的集合。

但显然，这两个句子的含义天差地别。顺序是语言理解的基础。

:::

我们必须显式地告诉模型每个词在序列中的位置，否则它就无法理解语言的逻辑结构。位置编码就是完成这个任务的 "位置说明书"。

## 自注意力

::: danger 警告

该部分尚未完工!

:::

**自注意力机制**是一种让序列中的每一个元素（例如句子中的每一个词）都能与序列中所有其他元素（包括它自己）进行直接交互，并根据相关性动态分配权重，从而生成一个新的、融合了全局上下文信息的表示向量的方法。

一般来说，自注意力机制的原理是通过检查每个词与句子中所有词（包括它自己）的相似度。

### 动态加权聚合

想象你在阅读这句话：

> "The animal didn't cross the street because it was too tired."
>
> （那只动物没有过马路，因为它太累了。）

作为人类，当你看到 "it" 时，你会立刻将注意力聚焦到 "animal" 上，而不是 "street"。自注意力机制所做的就是自动化这个过程。

所以，我们的目标就是为句子中的每个词（如 "it"）计算一个新的表示向量，通过考察句中所有词与 "it" 的相关性，对它们的值进行加权求和，得到新生成的 "it" 的向量会包含关于"animal" 的强烈信息，从而帮助模型理解 "it" 指代的是什么。

## 残差链接

::: danger 警告

该部分尚未完工!

:::

## 解码器

::: danger 警告

该部分尚未完工!

:::

## 小结

::: danger 警告

该部分尚未完工!

:::

::: details 专有名词

- **词嵌入**：使得 transformer 能够将单词编码成数字

- **位置编码**：使得 transformer 能够编码单词的位置

- **自注意力**：使得 transformer 能够编码单词之间的关系

- **残差链接**：使得 transformer 可以相对容易和快速地并行训练

:::
