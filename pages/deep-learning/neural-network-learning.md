# 神经网络的学习

::: danger 警告
该页面尚未完工!
:::

## 目录

[[toc]]

## 从数据中学习

神经网络的特征就是可以从数据中学习。所谓“从数据中学习”，是指可以由数据自动决定权重参数的值。

### 数据驱动

现在我们来思考一个具体的问题，比如如何实现数字“5”的识别，我们的目标是实现能区别是否是 5 的程序。

![手写数字5的例子](/images/deep-learning/neural-network-learning/fives.png)

如果让我们自己来设计一个能将 5 正确分类的程序，就会意外地发现这是一个很难的问题。人可以简单地识别出 5，但却很难明确说出是基于何种规律而识别出了 5。

因此，与其绞尽脑汁，从零开始想出一个可以识别 5 的算法，不如考虑通过有效利用数据来解决这个问题。一种方案是，先从图像中提取**特征量**，再用机器学习技术学习这些特征量的模式。

![从人工设计规则转变为由机器从数据中学习：没有人为介入的方块用灰色表示](/images/deep-learning/neural-network-learning/human-to-machine.png)

### 训练数据和测试数据

机器学习中，一般将数据分为**训练数据**和**测试数据**两部分来进行学习和实验。

首先，使用训练数据进行学习，寻找最优的参数；然后，使用测试数据评价训练得到的模型的实际能力。

::: info 泛化能力

泛化能力是指处理未被观察过的数据（不包含在训练数据中的数据）的能力。**获得泛化能力是机器学习的最终目标**。

比如，在识别手写数字的问题中，泛化能力可能会被用在自动读取明信片的邮政编码的系统上。此时，手写数字识别就必须具备较高的识别“某个人”写的字的能力。注意这里不是“特定的某个人写的特定的文字”，而是“任意一个人写的任意文字”。如果系统只能正确识别已有的训练数据，那有可能是只学习到了训练数据中的个人的习惯写法。

因此，仅仅用一个数据集去学习和评价参数，是无法进行正确评价的。这样会导致可以顺利地处理某个数据集，但无法处理其他数据集的情况。

:::

## 损失函数

神经网络的学习通过某个指标表示现在的状态。然后，以这个指标为基准，寻找最优权重参数。神经网络的学习中所用的指标称为**损失函数**（loss function）。这个损失函数可以使用任意函数，但一般用**均方误差**和**交叉熵误差**等。

### 均方误差

可以用作损失函数的函数有很多，其中最有名的是**均方误差**（mean squared error）。均方误差如下式所示：

$$E = \frac{1}{2} \sum_{k} (y_k - t_k)^2$$

这里，$y_k$ 是表示神经网络的输出，$t_k$ 表示监督数据，$k$ 表示数据的维数。

均方误差会计算神经网络的输出和正确解监督数据的各个元素之差的平方，再求总和。

```python
def mean_squared_error(y, t):
    return 0.5 * np.sum((y-t)**2)
```

::: details 手写数字识别的例子

$y_k$、$t_k$ 是由如下 10 个元素构成的数据：

```python
y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
```

数组元素的索引从第一个开始依次对应数字 0、1、2 ······ 这里，神经网络的输出 y 是 softmax 函数的输出。由于 softmax 函数的输出可以理解为概率，因此上例表示 0 的概率是 0.1，1 的概率是 0.05，2 的概率是 0.6 等。t 是监督数据，将正确解标签设为 1，其他均设为 0。这里，标签 2 为 1，表示正确解是 2。将正确解标签表示为 1，其他标签表示为 0 的表示方法称为 **one-hot 表示**。

```python
def mean_squared_error(y, t):
    return 0.5 * np.sum((y-t)**2)

t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 设“2”为正确解

y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] # 例1：“2”的概率最高的情况（0.6）
print(mean_squared_error(np.array(y), np.array(t))) # 0.097500000000000031

y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0] # 例2：“7”的概率最高的情况（0.6）
print(mean_squared_error(np.array(y), np.array(t))) # 0.59750000000000003
```

这里举了两个例子。第一个例子中，正确解是 2，神经网络的输出的最大值是 2；第二个例子中，正确解是 2，神经网络的输出的最大值是 7。 如实验结果所示，我们发现第一个例子的损失函数的值更小，和监督数据之间的误差较小。也就是说，均方误差显示第一个例子的输出结果与监督数据更加吻合。

:::

### 交叉熵误差

除了均方误差之外，**交叉熵误差**（cross entropy error）也经常被用作损失函数。交叉熵误差如下式所示：

$$E = - \sum_{k} t_k \log y_k$$

这里，log 表示以 e 为底数的自然对数（$log_e$）。 $y_k$ 是神经网络的输出，$t_k$ 是正确解标签。并且，$t_k$ 中只有正确解标签的索引为 1，其他均为 0（one-hot 表 示 ）。

::: tip 提示

该式实际上只计算对应正确解标签的输出的自然对数。

比如，假设正确解标签的索引是 2，与之对应的神经网络的输出是 0.6，则交叉熵误差是 $−log0.6 = 0.51$； 若 2 对应的输出是 0.1，则交叉熵误差为 $−log0.1=2.30$。也就是说，交叉熵误差的值是由正确解标签所对应的输出结果决定的。
:::

```python
def cross_entropy_error(y, t):
    delta = 1e-7
    return -np.sum(t * np.log(y + delta))
```

::: details 代码解释

这里，参数 y 和 t 是 NumPy 数组。函数内部在计算 np.log 时，加上了一个微小值 delta。这是因为，当出现 np.log(0) 时，np.log(0) 会变为负无限大的 -inf，这样一来就会导致后续计算无法进行。作为保护性对策，添加一个微小值可以防止负无限大的发生。

:::

::: details 实例解释

```python
def cross_entropy_error(y, t):
    delta = 1e-7
    return -np.sum(t * np.log(y + delta))

t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 设“2”为正确解

y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] # 例1：“2”的概率最高的情况（0.6）
print(cross_entropy_error(np.array(y), np.array(t))) # 0.51082545709933802

y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0] # 例2：“7”的概率最高的情况（0.6）
print(cross_entropy_error(np.array(y), np.array(t))) # 2.3025840929945458
```

第一个例子中，正确解标签对应的输出为 0.6，此时的交叉熵误差大约为 0.51。第二个例子中，正确解标签对应的输出为 0.1 的低值，此时的交叉熵误差大约为 2.3。

:::

### 平均损失函数

机器学习使用训练数据进行学习。使用训练数据进行学习，严格来说，就是针对训练数据计算损失函数的值，找出使该值尽可能小的参数。因此，计算损失函数时必须将所有的训练数据作为对象。也就是说，如果训练数据有 100 个的话，我们就要把这 100 个损失函数的总和作为学习的指标。

前面介绍的损失函数的例子中考虑的都是针对单个数据的损失函数。如果要求所有训练数据的损失函数的总和，以交叉熵误差为例，可以写成下面的式子：

$$E = -\frac{1}{N} \sum_{n} \sum_{k} t_{nk} \log y_{nk}$$

这里，假设数据有 N 个，$t_{nk}$ 表示第 n 个数据的第 k 个元素的值（$y_{nk}$ 是神经网络的输出，$t_{nk}$ 是监督数据）。

通过除以 N，可以求单个数据的“平均损失函数”。通过这样的平均化，可以获得和训练数据的数量无关的统一指标。比如，即便训练数据有 1000 个或 10000 个，也可以求得单个数据的平均损失函数。

### mini-batch 学习

MNIST 数据集的训练数据有 60000 个，如果以全部数据为对象求损失函数的和，则计算过程需要花费较长的时间。再者，如果遇到大数据，数据量会有几百万、几千万之多，这种情况下以全部数据为对象计算损失函数是不现实的。

因此，我们从全部数据中选出一部分，作为全部数据的“近似”。神经网络的学习也是从训练数据中选出一批数据（称为 mini-batch,小批量），然后对每个 mini-batch 进行学习。比如，从 60000 个训练数据中随机选择 100 笔，再用这 100 笔数据进行学习。这种学习方式称为 **mini-batch 学习**。

### mini-batch 版交叉熵误差的实现

::: code-group

```python [同时处理单个数据和批量数据（数据作为batch集中输入）]
def cross_entropy_error(y, t):
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
    batch_size = y.shape[0]
    return -np.sum(t * np.log(y + 1e-7)) / batch_size
```

```python [监督数据是标签形式（非one-hot表示，而是像2、7这样的标签）]
def cross_entropy_error(y, t):
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
    batch_size = y.shape[0]
    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size
```

:::

实现的要点是，由于 one-hot 表示中 t 为 0 的元素的交叉熵误差也为 0，因此针对这些元素的计算可以忽略。

### 为何要设定损失函数

假设有一个神经网络，现在我们来关注这个神经网络中的某一个权重参数。

此时，对该权重参数的损失函数求导，表示的是“如果稍微改变这个权重参数的值，损失函数的值会如何变化”。

如果导数的值为负，通过使该权重参数向正方向改变，可以减小损失函数的值；反过来，如果导数的值为正，则通过使该权重参数向负方向改变，可以减小损失函数的值。

不过，当导数的值为 0 时，无论权重参数向哪个方向变化，损失函数的值都不会改变，此时该权重参数的更新会停在此处。

::: info 总结

在进行神经网络的学习时，不能将识别精度作为指标。因为如果以识别精度为指标，则参数的导数在绝大多数地方都会变为 0。

:::

::: details 为什么用识别精度作为指标时，参数的导数在绝大多数地方都会变成 0 呢？

假设某个神经网络正确识别出了 100 笔训练数据中的 32 笔，此时识别精度为 32%。

如果以识别精度为指标，即使稍微改变权重参数的值，识别精度也仍将保持在 32%，不会出现变化。

也就是说，**仅仅微调参数，是无法改善识别精度的**。即便识别精度有所改善，它的值也不会像 32.0123...%这样连续变化，而是变为 33%、34% 这样的不连续的、离散的值。

而如果把损失函数作为指标，则当前损失函数的值可以表示为 0.92543...这样的值。并且，如果稍微改变一下参数的值，对应的损失函数也会像 0.93432...这样发生连续性的变化。

:::

## 数值微分

利用微小的差分求导数的过程称为**数值微分**（numerical differentiation），而基于数学式的推导求导数的过程，则用“**解析性**”（analytic）一词，称为“解析性求解”或者“解析性求导”。

### 导数

导数就是表示某个瞬间的变化量。它可以定义成下面的式子：

$$\frac{df(x)}{dx} = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}$$

左边的符号 $\frac{df(x)}{dx}$ 表示 $f(x)$ 关于 $x$ 的导数，即 $f(x)$ 相对于 $x$ 的变化程度。该式表示的导数的含义是，$x$ 的“微小变化”将导致函数 $f(x)$ 的值在多大程度上发生变化。

```python
def numerical_diff(f, x):
    h = 1e-4 # 0.0001
    return (f(x+h) - f(x-h)) / (2*h)
```

### 偏导数

接下来，我们看一下下面这个函数。虽然它只是一个计算参数的平方和的简单函数，但是请注意和上例不同的是，这里有两个变量：

$$f(x_0, x_1) = x_0^2 +  x_1^2$$

```python
def function_2(x):
    return x[0]**2 + x[1]**2
    # 或者return np.sum(x**2)
```

::: details 代码解释

这里，我们假定向参数输入了一个 NumPy 数组。函数的内部实现比较简单，先计算 NumPy 数组中各个元素的平方，再求它们的和（np.sum(x\*\*2)也可以实现同样的处理）。

:::

![函数图像](/images/deep-learning/neural-network-learning/function_2.png)

现在我们来求该函数的导数。这里需要注意的是，该函数有两个变量，所以有必要区分对哪个变量求导数，即对 $x_0$ 和 $x_1$ 两个变量中的哪一个求导数。另外，我们把这里讨论的有多个变量的函数的导数称为**偏导数**。用数学式表示的话，可以写成 $\frac{\partial f}{\partial x_0}$、$\frac{\partial f}{\partial x_1}$。

不过，偏导数需要将多个变量中的某一个变量定为目标变量，并将其他变量固定为某个值。

## 梯度

像 $(\frac{\partial f}{\partial x_0},\frac{\partial f}{\partial x_1})$ 这样的由全部变量的偏导数汇总而成的向量称为**梯度**（gradient）。

```python
def numerical_gradient(f, x):
    h = 1e-4 # 0.0001
    grad = np.zeros_like(x) # 生成和 x 形状相同、所有元素都为 0 的数组
    for idx in range(x.size):
        tmp_val = x[idx]
        # f(x+h) 的计算
        x[idx] = tmp_val + h
        fxh1 = f(x)
        # f(x-h) 的计算
        x[idx] = tmp_val - h
        fxh2 = f(x)
        grad[idx] = (fxh1 - fxh2) / (2*h)
        x[idx] = tmp_val # 还原值
    return grad
```

::: details 实例计算

```python
def function_2(x):
    return x[0]**2 + x[1]**2

print(numerical_gradient(function_2, np.array([3.0, 4.0]))) # [6. 8.]
print(numerical_gradient(function_2, np.array([0.0, 2.0]))) # [0. 4.]
print(numerical_gradient(function_2, np.array([3.0, 0.0]))) # [6. 0.]
```

:::

### 梯度法

机器学习的主要任务是在学习时寻找最优参数。同样地，神经网络也必须在学习时找到最优参数（权重和偏置）。这里所说的最优参数是指损失函数取最小值时的参数。

但是，一般而言，损失函数很复杂，参数空间庞大，我们不知道它在何处能取得最小值。而通过巧妙地使用梯度来寻找函数最小值（或者尽可能小的值）的方法就是**梯度法**（gradient method）。梯度法是解决机器学习中最优化问题的常用方法，特别是在神经网络的学习中经常被使用。

::: warning 注意

梯度表示的是各点处的函数值减小最多的方向。因此，无法保证梯度所指的方向就是函数的最小值或者真正应该前进的方向。实际上，在复杂的函数中，梯度指示的方向基本上都不是函数值最小处。

虽然梯度的方向并不一定指向最小值，但沿着它的方向能够最大限度地减小函数的值。因此，在寻找函数的最小值（或者尽可能小的值）的位置的任务中，要以梯度的信息为线索，决定前进的方向。

:::

在梯度法中，函数的取值从当前位置沿着梯度方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度方向前进，如此反复，不断地沿梯度方向前进，通过不断地沿梯度方向前进，逐渐减小函数值。

现在，我们尝试用数学式来表示梯度法：

$$x_0 = x_0 - \eta \frac{\partial f}{\partial x_0}$$

$$x_1 = x_1 - \eta \frac{\partial f}{\partial x_1}$$

这里的 $\eta$ 表示更新量，在神经网络的学习中，称为**学习率**（learning rate）。学习率决定在一次学习中，应该学习多少，以及在多大程度上更新参数。

::: tip 提示

该式是表示更新一次的式子，这个步骤会反复执行。也就是说，每一步都按该式更新变量的值，通过反复执行此步骤，逐渐减小函数值。

:::

```python
def gradient_descent(f, init_x, lr=0.01, step_num=100):
    x = init_x
    for i in range(step_num):
        grad = numerical_gradient(f, x)
        x -= lr * grad
    return x
```

::: details 代码解释

参数 f 是要进行最优化的函数，init_x 是初始值，lr 是学习率，step_num 是梯度法的重复次数。

`numerical_gradient(f,x)` 会求函数的梯度，用该梯度乘以学习率得到的值进行更新操作，由 step_num 指定重复的次数。

:::

::: details 实例计算

**问题**：请用梯度法求 $f(x_0+x_1) = x_0^2 + x_1^2$ 的最小值。

```python
def function_2(x):
    return x[0]**2 + x[1]**2

init_x = np.array([-3.0, 4.0])
print(gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100))
# [-6.11110793e-10  8.14814391e-10]
```

这里，设初始值为(-3.0, 4.0)，开始使用梯度法寻找最小值。最终的结果是(-6.1e-10, 8.1e-10)，非常接近(0，0)。实际上，真的最小值就是(0，0)，所以说通过梯度法我们基本得到了正确结果。

如果用图来表示梯度法的更新过程，则可以发现，原点处是最低的地方，函数的取值一点点在向其靠近。

![梯度法的更新过程](/images/deep-learning/neural-network-learning/gradient-method.png)

:::

::: warning 学习率过大或者过小都无法得到好的结果

```python
# 学习率过大的例子：lr=10.0
init_x = np.array([-3.0, 4.0])
print(gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100))
# array([ -2.58983747e+13,  -1.29524862e+12])

# 学习率过小的例子：lr=1e-10
init_x = np.array([-3.0, 4.0])
print(gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100))
# array([-2.99999994,  3.99999992])
```

学习率过大的话，会发散成一个很大的值；反过来，学习率过小的话，基本上没怎么更新就结束了。

也就是说，设定合适的学习率是一个很重要的问题。

:::

### 神经网络的梯度

神经网络的学习也要求梯度。这里所说的梯度是指损失函数关于权重参数的梯度。

::: details 实例计算

我们以一个简单的神经网络为例，来实现求梯度的代码。为此，我们要实现一个名为 simpleNet 的类：

```python
import sys, os
sys.path.append(os.pardir)
import numpy as np
from common.functions import softmax, cross_entropy_error
from common.gradient import numerical_gradient
class simpleNet:
    def __init__(self):
        self.W = np.random.randn(2,3) # 用高斯分布进行初始化
    def predict(self, x):
        return np.dot(x, self.W)
    def loss(self, x, t):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        return loss
```

这里使用了 `softmax`（输出层的概率函数） 、 `cross_entropy_error`（交叉熵损失函数）以及 `numerical_gradient`（梯度计算）方法。

simpleNet 类只有一个实例变量，即形状为 2×3 的权重参数。它有两个方法，一个是用于预测的 `predict(x)`，另一个是用于求损失函数值的 `loss(x,t)`。这里参数 x 接收输入数据，t 接收正确解标签。

现在我们来试着用一下这个 simpleNet 类：

```python
net = simpleNet()
print("权重参数：",net.W) # 权重参数
x = np.array([0.6, 0.9])
p = net.predict(x)
print("预测结果：",p)
print("最大值的索引：",np.argmax(p))
t = np.array([0, 0, 1]) # 正确解标签
print("损失函数：",net.loss(x, t))
```

接下来求梯度。和前面一样，我们使用 `numerical_gradient(f, x)` 求梯度度：

```python
def f(W):
    return net.loss(x, t)
dW = numerical_gradient(f, net.W)

# lambda 表示法
# f = lambda w: net.loss(x, t)
# dW = numerical_gradient(f, net.W)

print("梯度计算结果",dW)
```

（这里定义的函数 f(W)的参数 W 是一个伪参数。因为 `numerical_gradient(f, x)`会在内部执行 f(x),为了与之兼容而定义了 f(W)）

`numerical_gradient(f, x)` 的参数 f 是函数，x 是传给函数 f 的参数。因此，这里参数 x 取 net.W，并定义一个计算损失函数的新函数 f，然后把这个新定义的函数传递给 `numerical_gradient(f, x)`。

:::

求出神经网络的梯度后，接下来只需根据梯度法，更新权重参数即可。

## 学习算法的实现
